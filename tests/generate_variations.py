#!/usr/bin/env python3
"""
Generate prompt variations for testing based on reference conversations.
Creates variations of user prompts while keeping the reference data for semantic analysis.
"""

import csv
import random
import re
from typing import List, Dict, Tuple

def generate_prompt_variations(reference_file: str) -> Dict[str, List[str]]:
    """
    Generate variations of prompts based on reference conversations.
    
    Args:
        reference_file: Path to reference conversations CSV
        
    Returns:
        Dictionary of categorized prompt variations
    """
    
    # Load reference data
    reference_data = []
    with open(reference_file, 'r', encoding='utf-8') as file:
        reader = csv.DictReader(file)
        for row in reader:
            reference_data.append({
                'user_message': row['user_message'].strip(),
                'response': row['response'].strip()
            })
    
    # Generate variations
    variations = {
        'myanmar_internet_outage': [],
        'myanmar_billing_payment': [],
        'myanmar_technical_support': [],
        'myanmar_product_inquiry': [],
        'myanmar_customer_service': [],
        'myanmar_mixed_language': []
    }
    
    for data in reference_data:
        user_msg = data['user_message']
        category = categorize_conversation(user_msg, data['response'])
        
        # Generate variations for each original prompt
        prompt_variations = create_variations(user_msg)
        
        # Add to appropriate category
        if category in variations:
            variations[category].extend(prompt_variations)
    
    # Remove duplicates while preserving order
    for category in variations:
        seen = set()
        unique_variations = []
        for variation in variations[category]:
            if variation not in seen:
                seen.add(variation)
                unique_variations.append(variation)
        variations[category] = unique_variations
    
    return variations

def categorize_conversation(user_msg: str, response: str) -> str:
    """Categorize conversation based on content analysis."""
    
    # Keywords for different categories
    outage_keywords = ['·Äú·Ä≠·ÄØ·ÄÑ·Ä∫·Ä∏·Äô·ÄÄ·Ä±·Ä¨·ÄÑ·Ä∫·Ä∏', '·Äú·Ä≠·ÄØ·ÄÑ·Ä∫·Ä∏·ÄÄ·Äª', '·Ä°·ÄÑ·Ä∫·Äê·Ä¨·Äî·ÄÄ·Ä∫·Äô·Äõ', '·Äú·Ä≠·ÄØ·ÄÑ·Ä∫·Ä∏·Äï·Äº·Äê·Ä∫', '·Äú·Ä≠·ÄØ·ÄÑ·Ä∫·Ä∏·Äî·Äæ·Ä±·Ä∏', '·Äô·Äõ·Äò·Ä∞·Ä∏', '·Äï·Äº·Äê·Ä∫·Äî·Ä±', '·Äú·Ä≠·ÄØ·ÄÑ·Ä∫·Ä∏·Äú·ÄØ·Ä∂·Ä∏·Äù·Äô·ÄÄ·Ä±·Ä¨·ÄÑ·Ä∫·Ä∏']
    billing_keywords = ['·Äò·Ä±·Äú·Ä∫·ÄÜ·Ä±·Ä¨·ÄÑ·Ä∫', '·ÄÑ·ÄΩ·Ä±·Äï·Ä±·Ä∏·ÄÜ·Ä±·Ä¨·ÄÑ·Ä∫', '·ÄÄ·Äº·Ä±·Ä∏', '·Äò·Ä±·ÄÜ·Ä±·Ä¨·ÄÑ·Ä∫', '·ÄÑ·ÄΩ·Ä±·Äñ·Äº·Ää·Ä∑·Ä∫', '·Äï·Ä±·Ä∏·ÄÜ·Ä±·Ä¨·ÄÑ·Ä∫', '·Äò·Ä±·Äú·Ä∫·Äï·Ä±·Ä∏·ÄÜ·Ä±·Ä¨·ÄÑ·Ä∫', '·ÄÑ·ÄΩ·Ä±·ÄÅ·Äª·Ä±']
    technical_keywords = ['wifi', 'Wi-Fi', '·ÄÅ·Äª·Ä≠·Äê·Ä∫·Äô·Äõ', '·ÄÅ·Äª·Ä≠·Äê·Ä∫·ÄÜ·ÄÄ·Ä∫', 'password', '·Äï·Ä´·ÄÖ·Ä∫·Äù·Ä´', '·ÄÄ·Äí·Ä∫·Äï·Äª·ÄÄ·Ä∫', '·ÄÅ·Ä≤·ÄÅ·Äº·ÄÖ·Ä∫', '·Äï·Äª·ÄÄ·Ä∫·Äû·ÄΩ·Ä¨·Ä∏']
    product_keywords = ['·Äï·ÄÄ·Ä∫·ÄÄ·Ä±·Ä∑·ÄÇ·Ä∫', '·Ä°·Äù·Äû·ÄØ·Ä∂·Ä∏', '·ÄÄ·Äí·Ä∫', '·Äï·Äú·Äî·Ä∫', '·Äà·Ä±·Ä∏·Äî·Äæ·ÄØ·Äî·Ä∫·Ä∏', '·Ä°·Äô·Äº·Äî·Ä∫·Äî·Äæ·ÄØ·Äî·Ä∫·Ä∏', 'Mbps', '·ÄÄ·Äê·Ä∫·Äê·ÄΩ·Ä±', '·Äï·Äú·Äî·Ä∫·Äê·ÄΩ·Ä±']
    service_keywords = ['customer service', '·Äñ·ÄØ·Äî·Ä∫·Ä∏·Äî·Ä∂·Äï·Ä´·Äê·Ä∫', '·ÄÜ·ÄÄ·Ä∫·Äû·ÄΩ·Äö·Ä∫', '·Ä°·ÄÄ·Ä∞·Ä°·Ää·ÄÆ', '·Äï·Äº·Ä±·Ä¨·ÄÅ·Äª·ÄÑ·Ä∫', '·Äñ·ÄØ·Äî·Ä∫·Ä∏·Äî·Ä∂·Äï·Ä´·Äê·Ä∫·Äû·Ä≠·ÄÅ·Äª·ÄÑ·Ä∫']
    
    # Check for mixed language (English + Myanmar)
    has_english = bool(re.search(r'[a-zA-Z]', user_msg))
    has_myanmar = bool(re.search(r'[\u1000-\u109F]', user_msg))
    
    if has_english and has_myanmar:
        return 'myanmar_mixed_language'
    
    # Check categories
    if any(keyword in user_msg for keyword in outage_keywords):
        return 'myanmar_internet_outage'
    elif any(keyword in user_msg for keyword in billing_keywords):
        return 'myanmar_billing_payment'
    elif any(keyword in user_msg for keyword in technical_keywords):
        return 'myanmar_technical_support'
    elif any(keyword in user_msg for keyword in product_keywords):
        return 'myanmar_product_inquiry'
    elif any(keyword in user_msg for keyword in service_keywords):
        return 'myanmar_customer_service'
    else:
        return 'myanmar_mixed_language'

def create_variations(original_prompt: str) -> List[str]:
    """
    Create variations of a prompt while maintaining semantic meaning.
    
    Args:
        original_prompt: Original prompt text
        
    Returns:
        List of prompt variations
    """
    variations = [original_prompt]  # Include original
    
    # Variation patterns for Myanmar text
    variation_patterns = [
        # Add politeness markers
        lambda text: f"·Äô·ÄÑ·Ä∫·Äπ·ÄÇ·Äú·Ä¨·Äï·Ä´ {text}",
        lambda text: f"{text} ·ÄÅ·ÄÑ·Ä∫·Äó·Äª·Ä¨",
        lambda text: f"{text} ·Äõ·Äæ·ÄÑ·Ä∑·Ä∫",
        
        # Add urgency indicators
        lambda text: f"·Ä°·Äõ·Ä±·Ä∏·ÄÄ·Äº·ÄÆ·Ä∏·Äï·Ä´·Äê·Äö·Ä∫ {text}",
        lambda text: f"·Ä°·Äô·Äº·Äî·Ä∫·ÄÜ·ÄØ·Ä∂·Ä∏ {text}",
        lambda text: f"·Ä°·Äõ·Ä±·Ä∏·Äê·ÄÄ·Äº·ÄÆ·Ä∏ {text}",
        
        # Add context
        lambda text: f"·Ä°·Ä≠·Äô·Ä∫·Äô·Äæ·Ä¨ {text}",
        lambda text: f"·Äõ·ÄØ·Ä∂·Ä∏·Äô·Äæ·Ä¨ {text}",
        lambda text: f"·Ä°·Äú·ÄØ·Äï·Ä∫·Äô·Äæ·Ä¨ {text}",
        
        # Simplify complex sentences
        lambda text: simplify_sentence(text),
        
        # Add emotional context
        lambda text: f"·ÄÖ·Ä≠·Äê·Ä∫·Äõ·Äæ·ÄØ·Äï·Ä∫·Äî·Ä±·Äï·Ä´·Äê·Äö·Ä∫ {text}",
        lambda text: f"·Ä°·ÄÜ·ÄÑ·Ä∫·Äô·Äï·Äº·Ä±·Äê·Ä¨ {text}",
    ]
    
    # Apply variations
    for pattern in variation_patterns:
        try:
            variation = pattern(original_prompt)
            if variation != original_prompt and len(variation) < 200:  # Keep reasonable length
                variations.append(variation)
        except:
            continue
    
    # Add some English variations for mixed language prompts
    if re.search(r'[a-zA-Z]', original_prompt):
        english_variations = [
            lambda text: text.replace("I want to", "I need to"),
            lambda text: text.replace("How to", "Can you help me"),
            lambda text: text.replace("?", " please?"),
            lambda text: f"Hello, {text}",
            lambda text: f"Hi, {text}",
        ]
        
        for pattern in english_variations:
            try:
                variation = pattern(original_prompt)
                if variation != original_prompt:
                    variations.append(variation)
            except:
                continue
    
    # Limit to reasonable number of variations
    return variations[:8]  # Max 8 variations per original prompt

def simplify_sentence(text: str) -> str:
    """Simplify complex Myanmar sentences."""
    # Remove some complex parts while keeping core meaning
    simplifications = [
        (r'·Ä°·ÄÜ·ÄÑ·Ä∫·Äô·Äï·Äº·Ä±·Äô·Äæ·ÄØ·Äô·Äª·Ä¨·Ä∏·Ä°·Äê·ÄΩ·ÄÄ·Ä∫·Äê·Ä±·Ä¨·ÄÑ·Ä∫·Ä∏·Äï·Äî·Ä∫·Äï·Ä´·Äê·Äö·Ä∫·Åã', ''),
        (r'·Äú·Ä∞·ÄÄ·Äº·ÄÆ·Ä∏·Äô·ÄÑ·Ä∫·Ä∏·Åè', ''),
        (r'·Äï·Ä±·Ä∏·Äï·Ä≠·ÄØ·Ä∑·Äï·Äº·ÄÆ·Ä∏·Äû·Ä¨·Ä∏·Äñ·Äº·ÄÖ·Ä∫·Äï·Ä´·ÄÄ·Äë·Äï·Ä∫·Äô·Ä∂·Äï·Ä±·Ä∏·Äï·Ä≠·ÄØ·Ä∑·Äõ·Äî·Ä∫·Äô·Äú·Ä≠·ÄØ·Äï·Ä´·ÄÅ·ÄÑ·Ä∫·Äó·Äª·Ä¨·Åã', ''),
        (r'Customer service agent·ÄÜ·ÄÆ·Äû·Ä≠·ÄØ·Ä∑·Äú·ÄΩ·Äæ·Ä≤·Äï·Ä±·Ä∏·Äï·Ä´·Äô·Äö·Ä∫·ÄÅ·ÄÑ·Ä∫·Äó·Äª·Ä¨·Åã', ''),
        (r'Message ·Äô·Äª·Ä¨·Ä∏·ÄÄ·Ä≠·ÄØ ·Ä°·Äú·Äæ·Ää·Ä∑·Ä∫·ÄÄ·Äª·Äï·Äº·Äî·Ä∫·Äú·Ää·Ä∫·Äñ·Äº·Ä±·ÄÄ·Äº·Ä¨·Ä∏·Äï·Ä±·Ä∏·Äô·Äæ·Ä¨·Äñ·Äº·ÄÖ·Ä∫·Äê·Ä≤·Ä∑·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ ·Ä°·ÄÅ·Äª·Ä≠·Äî·Ä∫·ÄÅ·Äè·Äú·Ä±·Ä¨·ÄÄ·Ä∫·ÄÖ·Ä±·Ä¨·ÄÑ·Ä∑·Ä∫·ÄÜ·Ä≠·ÄØ·ÄÑ·Ä∫·Ä∏·Äï·Ä±·Ä∏·Äõ·Äî·Ä∫ ·Äô·Ä±·Äê·Äπ·Äê·Ä¨·Äõ·Äï·Ä∫·ÄÅ·Ä∂·Ä°·Äï·Ä∫·Äï·Ä´·Äê·Äö·Ä∫·Åã', ''),
    ]
    
    simplified = text
    for pattern, replacement in simplifications:
        simplified = re.sub(pattern, replacement, simplified)
    
    # Clean up extra spaces
    simplified = re.sub(r'\s+', ' ', simplified).strip()
    
    return simplified if simplified != text else text

def generate_fixtures_code(variations: Dict[str, List[str]]) -> str:
    """Generate the updated fixtures code with variations."""
    
    code = '''# Test Fixtures for vLLM Performance Testing
# Contains various prompt categories with variations for testing different models

# General English prompts for LLM1 (Gemma)
general_prompts = [
    "Hello! How are you today?",
    "What is the capital of France?",
    "Explain quantum computing in simple terms.",
    "Write a short poem about the ocean.",
    "What are the benefits of renewable energy?",
    "Tell me a joke.",
    "How do you make a sandwich?",
    "What is machine learning?",
    "Describe the weather today.",
    "What is your favorite color and why?",
    "Explain photosynthesis briefly.",
    "What is the meaning of life?",
    "How do computers work?",
    "Tell me about space exploration.",
    "What is artificial intelligence?",
]

# Myanmar language prompt variations for testing
# Generated from reference conversations with semantic variations
'''
    
    # Add each category with variations
    for category, prompts in variations.items():
        if prompts:
            code += f'\n# {category.replace("_", " ").title()} prompts\n'
            code += f'{category} = [\n'
            for prompt in prompts:  # Use all prompts
                code += f'    "{prompt}",\n'
            code += ']\n'
    
    # Add combined category
    all_myanmar_prompts = []
    for category, prompts in variations.items():
        if category.startswith('myanmar_'):
            all_myanmar_prompts.extend(prompts)
    
    code += f'''
# Combined Myanmar prompts for LLM2
myanmar_combined_prompts = {all_myanmar_prompts}

# Technical prompts for both models
technical_prompts = [
    "What is the difference between HTTP and HTTPS?",
    "Explain how DNS works.",
    "What is a VPN and how does it work?",
    "Describe the OSI model layers.",
    "What is the difference between TCP and UDP?",
    "How does SSL/TLS encryption work?",
    "What is load balancing?",
    "Explain microservices architecture.",
    "What is containerization?",
    "How does caching improve performance?",
]

# Creative prompts for both models
creative_prompts = [
    "Write a short story about a robot.",
    "Create a poem about technology.",
    "Describe a futuristic city.",
    "Write a dialogue between two AI systems.",
    "Create a haiku about the internet.",
    "Describe a day in the life of a programmer.",
    "Write a limerick about cybersecurity.",
    "Create a short script for a tech comedy.",
    "Describe an alien's first encounter with Earth's internet.",
    "Write a song about digital transformation.",
]

# Customer service prompts
customer_service_prompts = [
    "How can I reset my password?",
    "I forgot my username, what should I do?",
    "How do I contact customer support?",
    "What are your business hours?",
    "How can I cancel my subscription?",
    "I want to upgrade my plan, how do I do that?",
    "How do I get a refund?",
    "What payment methods do you accept?",
    "How do I update my billing information?",
    "I'm having trouble logging in, can you help?",
]

# All prompts combined
all_prompts = {{
    "general": general_prompts,
'''
    
    # Add Myanmar categories
    for category, prompts in variations.items():
        if category.startswith('myanmar_'):
            code += f'    "{category}": {category},\n'
    
    code += '''    "myanmar_combined": myanmar_combined_prompts,
    "technical": technical_prompts,
    "creative": creative_prompts,
    "customer_service": customer_service_prompts,
}
'''
    
    return code

def main():
    """Generate prompt variations and update fixtures."""
    print("üîÑ Generating prompt variations from reference conversations...")
    
    # Generate variations
    import os
    csv_path = os.path.join(os.path.dirname(__file__),
                            'reference_conversions.csv')
    variations = generate_prompt_variations(csv_path)
    
    # Print statistics
    print("\nüìä Generated Prompt Variations:")
    total_variations = 0
    for category, prompts in variations.items():
        if prompts:
            print(f"  {category}: {len(prompts)} variations")
            total_variations += len(prompts)
    
    print(f"\nüìù Total variations generated: {total_variations}")
    
    # Generate fixtures code
    print("\n‚úçÔ∏è Generating updated fixtures...")
    fixtures_code = generate_fixtures_code(variations)
    
    # Write to file
    import os
    fixtures_path = os.path.join(os.path.dirname(__file__), 'test_fixtures.py')
    with open(fixtures_path, 'w', encoding='utf-8') as f:
        f.write(fixtures_code)
    
    print("‚úÖ Updated test_fixtures.py with prompt variations!")
    print("\nüí° Usage:")
    print("  - Reference conversations are used for semantic analysis")
    print("  - Prompt variations are used for testing LLM responses")
    print("  - Run: python3 -m tests.demo_semantic to test semantic analysis")

if __name__ == "__main__":
    main()


